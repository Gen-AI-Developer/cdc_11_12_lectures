# Operating systems
An operating system is a specialized collection of software that stands between a computer’s hardware architecture and its applications. It performs a number of fundamental activities such as file system management, process scheduling, memory allocation, network interfacing, and resource sharing among the computer’s users. Operating systems have evolved in their complexity over time, beginning with the earliest computers in the 1960s.

With early computers, the user typed programs onto punched tape or cards, which were read into the computer, assembled or compiled, and run. The results were then transmitted to a printer or a magnetic tape. These early operating systems engaged in batch processing; i.e., handling sequences of jobs that are compiled and executed one at a time without intervention by the user. Accompanying each job in a batch were instructions to the operating system (OS) detailing the resources needed by the job, such as the amount of CPU time required, the files needed, and the storage devices on which the files resided. From these beginnings came the key concept of an operating system as a resource allocator. This role became more important with the rise of multiprogramming, in which several jobs reside in the computer simultaneously and share resources, for example, by being allocated fixed amounts of CPU time in turn. More sophisticated hardware allowed one job to be reading data while another wrote to a printer and still another performed computations. The operating system thus managed these tasks in such a way that all the jobs were completed without interfering with one another.

The advent of time sharing, in which users enter commands and receive results directly at a terminal, added more tasks to the operating system. Processes known as terminal handlers were needed, along with mechanisms such as interrupts (to get the attention of the operating system to handle urgent tasks) and buffers (for temporary storage of data during input/output to make the transfer run more smoothly). Modern large computers interact with hundreds of users simultaneously, giving each one the perception of being the sole user.

Another area of operating system research is the design of virtual memory. Virtual memory is a scheme that gives users the illusion of working with a large block of contiguous memory space (perhaps even larger than real memory), when in actuality most of their work is on auxiliary storage (disk). Fixed-size blocks (pages) or variable-size blocks (segments) of the job are read into main memory as needed. Questions such as how much main memory space to allocate to users and which pages or segments should be returned to disk (“swapped out”) to make room for incoming pages or segments must be addressed in order for the system to execute jobs efficiently.

The first commercially viable operating systems were developed by IBM in the 1960s and were called OS/360 and DOS/360. Unix was developed at Bell Laboratories in the early 1970s and since has spawned many variants, including Linux, Berkeley Unix, GNU, and Apple’s iOS. Operating systems developed for the first personal computers in the 1980s included IBM’s (and later Microsoft’s) DOS, which evolved into various flavors of Windows. An important 21st-century development in operating systems was that they became increasingly machine-independent.